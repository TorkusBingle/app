#!/usr/bin/env python
# coding: utf-8

# In[6]:


('writefile', 'appteam3.py', 'import os\nimport pandas as pd\nimport streamlit as st\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\nimport statsmodels.api as sm\nfrom dateutil.relativedelta import relativedelta\nfrom datetime import datetime\nimport plotly.express as px\nfrom IPython import get_ipython\n\nmigrant_App = pd.read_csv(\'migrant_clean.csv\', index_col=None)\ntimeseriesdf = pd.read_csv(\'timeseriesdf.csv\')\ntimeseriesdf[\'date\'] = pd.to_datetime(timeseriesdf[\'date\'])\ntimeseriesdf.set_index(\'date\', inplace=True)\n\ncolumn_names = migrant_App.columns\nprint(column_names)\n\nst.set_page_config(page_title="Migrant Web App", page_icon=":tada:", layout="wide")\n\n# Create a multiselect for navigation\nselected_sections = st.sidebar.selectbox("Select Sections", ["Introduction","Data Exploration (EDA)", "Modeling"])\n\nintroduction ="""\n        \n         Migration is a globally significant phenomenon with far-reaching impacts on \n         economies and societies. Our project analyzes the Global Missing Migrants \n         dataset to uncover the key factors contributing to migration incidents and \n         develop predictions for future occurrences. This application empowers users \n         to understand the likelihood of such incidents, providing valuable insights \n         for a safer migration experience and informed policy development.\n         \n         Introducing our app, it offers two core features: Exploratory Data Analysis \n         (EDA) and Time Series Analysis. Our EDA section provides insights into the \n         dataset, while the Time Series component allows users to predict future \n         migration incidents based on input parameters. """\n\nif "Data Exploration (EDA)" in selected_sections:\n    st.write("""To the right, you will find a menu of user inputs where you can explore and analyze the historical data related to missing migrants. \n    You can filter the data based on different criteria such as location, category, number of people, gender, and more. This analysis will help you \n    gain insights into the patterns and characteristics of incidents involving missing migrants. Additionally, you can visualize the main causes of \n    incidents in various migration routes. """)\n\n    # Sidebar\n    st.sidebar.header("User Inputs")\n    incident_year = st.sidebar.slider("Select Incident Year", 2014, 2023)\n    region_of_origin = st.sidebar.selectbox("Select Region of Origin", migrant_App["region of origin group"].unique())\n    number_of_males = st.sidebar.number_input("Number of Males", min_value=0)\n\n    # Main content\n    st.header("Migrant Data Analysis")\n\n    # Group data by "Region of Origin"\n    grouped_data = migrant_App.groupby("region of origin group").agg({\n        "number of males": "sum",\n        "number of females": "sum",\n        "number of children": "sum",\n        "total number of dead and missing": "sum"\n    })\n\n    # Display the aggregated data\n    st.write("Aggregated Data by Region:")\n    st.write(grouped_data)\n\n    # Plot the results (we can customize othr chart type)\n    st.bar_chart(grouped_data)\n\n    # User inputs\n    st.write("User Inputs:")\n    st.write(f"Incident Year: {incident_year}")\n    st.write(f"Region of Origin: {region_of_origin}")\n    st.write(f"Number of Males: {number_of_males}")\n\n    # Filter data based on user inputs\n    filtered_data = migrant_App[(migrant_App["incident year"] == incident_year) &\n                            (migrant_App["region of origin group"] == region_of_origin) &\n                            (migrant_App["number of males"] == number_of_males)]\n\n    if not filtered_data.empty:\n        # Display filted data\n        st.subheader("Analysis Results")\n        st.write("Number of Dead:", filtered_data["number of dead"].values[0])\n        st.write("Estimated number of Missings:", filtered_data["minimum estimated number of missing"].values[0])\n        st.write("Number of Dead and Missing:", filtered_data["total number of dead and missing"].values[0])\n        st.write("Number of Survivors:", filtered_data["number of survivors"].values[0])\n        st.write("Number of Females:", filtered_data["number of females"].values[0])\n        st.write("Number of Children:", filtered_data["number of children"].values[0])\n        st.write("Cause of Death:", filtered_data["cause of death category"].values[0])\n        st.write("Country of Death:", filtered_data["extracted country"].values[0])\n    else:\n        st.warning("No data available for the selected inputs.")\n\n# Additional features..............\n# Check if "Modeling" is in the selected sections\nelif "Modeling" in selected_sections:\n    # Header\n    st.write("To the right you will see a menu of user inputs where you can input the time and migration route you are planning on taking, this will then output an estimation of number of incidents based on the historicals. To the right of this timeseries you will also see the main causes of death in the migration route")\n    # Sidebar\n    st.sidebar.header("User Inputs")\n    planned_migration_date = st.sidebar.date_input("Input planned migration date", value="today", min_value=None, max_value=None, format="YYYY-MM-DD")\n\n    migration_route = st.sidebar.selectbox("Select Migration Route", timeseriesdf["migration route"].unique())\n    st.subheader("Time Series Model")\n    #function that returns the level of the migration route inputted\n    def getLevelOfRoute(route, timeseriesdf):\n        level = timeseriesdf[timeseriesdf[\'migration route\'] == route][\'label_level\'].values[0]\n        return level\n\n    #run the function with the migration route inputted   \n    ts_level = getLevelOfRoute(migration_route, timeseriesdf)\n    \n    #function to get all the df entries with the same level \n    def getClusterLabel(level, timeseries):\n        return (timeseries[timeseries[\'label_level\'] == level])\n\n    #function that extracts all the routes in the same cluster and groups them by the target variable.\n    def preprocess_level_timeseries(level, timeseries):\n        # Get the \'level\' timeseries\n        level_timeseries = getClusterLabel(level, timeseries)\n    \n        # Drop the \'date\' column\n        level_timeseries = level_timeseries.drop([\'date.1\'], axis=1)\n    \n        # Group by date and sum the \'total number of dead and missing\'\n        level_timeseries = level_timeseries.groupby(level_timeseries.index)[\'total number of dead and missing\'].sum()\n    \n        return level_timeseries\n\n    leveldf = preprocess_level_timeseries(ts_level, timeseriesdf)\n    \n    #the parameters will depend on the level selected \n    #if ts_level = \'level1\' then app_order = (1, 1, 1) \n    #if ts_level = \'level2\' or ts_level = \'level5\' then app_order = (1, 0, 0) \n    #if ts_level = \'level3\' or ts_level = \'level4\' then app_order = (0, 1, 1) \n    if ts_level == \'level1\':\n        app_order = (1, 1, 1)\n    elif ts_level == \'level2\' or ts_level == \'level5\':\n        app_order = (1, 0, 0)\n    elif ts_level == \'level3\' or ts_level == \'level4\':\n        app_order = (0, 1, 1)\n\n    #function that gets the number of periods for the sarima model \n\n    def calculate_months_difference(date1, date2):\n        date1 = pd.to_datetime(date1, format="%Y-%m-%d")\n        date2 = pd.to_datetime(date2, format="%Y-%m-%d")\n\n        rdelta = relativedelta(date2, date1)\n        months_difference = rdelta.years * 12 + rdelta.months\n\n        return months_difference\n\n    last_date = leveldf.index[-1]\n    target_date = planned_migration_date\n    months_difference = calculate_months_difference(last_date, target_date)\n\n    #function that sets the sarima timeseries model \n    def sarima_forecast(level_timeseries,forecast_months, order, seasonal_order, plot_title="SARIMA Forecast"):\n        # Create the SARIMA model\n        level_sarima_model = sm.tsa.SARIMAX(level_timeseries, order=order, seasonal_order=seasonal_order)\n        level_sarima_model_fit = level_sarima_model.fit()\n\n        # Make forecasts\n        forecasts = level_sarima_model_fit.get_forecast(steps=forecast_months)\n        predicted_values = forecasts.predicted_mean\n        predicted_values.index = pd.date_range(start=last_date, periods=forecast_months, freq=\'M\')\n\n        return predicted_values\n    #run the sarima function\n    predicted_values = sarima_forecast(leveldf, months_difference, order=app_order, seasonal_order=(1, 1, 1, 12), plot_title="Migrant Incident Forecast")\n\n    #function to retrieve the output of the timeseries for the inputted date\n    def get_values_for_year_month(indexes, values, year, month):\n        matching_values_string = ""  # Initialize an empty string\n        for i, date_index in enumerate(indexes):\n            if date_index.year == year and date_index.month == month:\n                matching_values_string += str(values[i])  # Convert values to strings and append to the string\n        return matching_values_string\n\n    # Example usage:\n    year_to_find = planned_migration_date.year\n    month_to_find = planned_migration_date.month\n    matching_values = get_values_for_year_month(predicted_values.index, predicted_values, year_to_find, month_to_find)\n    st.write(f"Estimated number of incidents for the planned migration date {month_to_find}/{year_to_find}: {matching_values}")\n\n    #declaration of columns\n    col1, col2 = st.columns(2)\n    \n    col1.subheader(f\'{migration_route} Number of Incidents Forecast\')\n    col1.write(f"The migration route was classified as a danger {ts_level}.")\n\n    # Create a new figure using Plotly Express\n    fig = px.line()\n    # Add historical data to the plot\n    fig.add_scatter(x=leveldf.index, y=leveldf, name="Historical Data")\n    # Add SARIMA forecast to the plot\n    fig.add_scatter(x=predicted_values.index, y=predicted_values, name="SARIMA Forecast", line=dict(color=\'red\'))\n    # Customize the layout (titles, labels, etc.)\n    fig.update_layout(\n        title="Migrant Incident Forecast",\n        xaxis_title="Year",\n        yaxis_title="Total Number of Incidents",\n        width=500,  # Set the width in pixels\n        height=400  # Set the height in pixels\n    )\n    \n    # Show the interactive plot\n    col1.plotly_chart(fig)\n\n    # Create a time slider\n    #time_range = col2.slider("Select a time range", 0, 14, (0, 23))\n \n    # Update the datetime slider based on the selected time range\n    #start_date = datetime(2014, 1, 1, time_range[0])\n    #end_date = datetime(2025, 12, 30)\n    #end_date = start_date + timedelta(hours=time_range[1] - time_range[0])\n \n    # selected_date = slider_placeholder.slider(\n    #     "Select a date range",\n    #     min_value=start_date,\n    #     max_value=end_date,\n    #     value=(start_date, end_date),\n    #     step=timedelta(hours=1),\n    # )\n\n    #link to slider code i found https://docs.kanaries.net/topics/Python/streamlit-datetime-slider\n\n    #visualizing COD\n    #col2.title(\'Cause of Death per migration route\')\n\n    # Creates route selection dropdown\n    #migration_routes = migrant_App[\'migration route\'].unique()\n    #commented out this dropdown and set up the cause of death to be determined by the selection of route in the user input side menu\n    #selected_route = st.selectbox(\'Please Select a Migration Route\', migration_routes)\n\n    # Filters the data based on the selected migration route\n    filtered_data = migrant_App[migrant_App[\'migration route\'] == migration_route]\n\n    # Creates the histogram\n    col2.subheader(f\'Causes of Death for {migration_route}\')\n    fig = px.histogram(filtered_data, x=\'Cause of Death Category\')\n    fig.update_layout(\n        width=600,  # Set the width in pixels\n        height=400  # Set the height in pixels\n    )\n    col2.plotly_chart(fig)\n\nelse: \n    # Header Section\n    st.header("Migration Data Analysis")\n    st.subheader("Welcome to the Migration Incident Prevention App")\n    st.write(introduction)\n    \n    \n# Footer\nst.sidebar.text("© 2023 Migrant Data Analysis App")\n\n\n\n')


# In[ ]:


("streamlit run appteam3.py --server.port=8080 --browser.serverAddress='0.0.0.0'")


# In[ ]:




